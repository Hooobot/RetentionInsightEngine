{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./.venv/lib/python3.12/site-packages (3.8.1)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.1)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.39.0)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.12/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./.venv/lib/python3.12/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.venv/lib/python3.12/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.12/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: SpeechRecognition in ./.venv/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: pydub in ./.venv/lib/python3.12/site-packages (0.25.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.12/site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.12/site-packages (from SpeechRecognition) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.26.0->SpeechRecognition) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.26.0->SpeechRecognition) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: jupyter in ./.venv/lib/python3.12/site-packages (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk pandas transformers\n",
    "%pip install SpeechRecognition pydub\n",
    "%pip install -U jupyter ipywidgets\n",
    "%pip install --upgrade setuptools\n",
    "%pip install torch torchvision torchaudio\n",
    "%pip install tensorflow\n",
    "%pip install tensorflow --upgrade\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nNo module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/VS Code/RetentionInsightEngine/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1472\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/VS Code/RetentionInsightEngine/.venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:26\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedFeatureExtractor\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_processing_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseImageProcessor\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_auto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoConfig\n",
      "File \u001b[0;32m~/VS Code/RetentionInsightEngine/.venv/lib/python3.12/site-packages/transformers/image_processing_utils.py:28\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchFeature \u001b[38;5;28;01mas\u001b[39;00m BaseBatchFeature\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m center_crop, normalize, rescale\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChannelDimension\n",
      "File \u001b[0;32m~/VS Code/RetentionInsightEngine/.venv/lib/python3.12/site-packages/transformers/image_transforms.py:47\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_flax_available():\n",
      "File \u001b[0;32m~/VS Code/RetentionInsightEngine/.venv/lib/python3.12/site-packages/tensorflow/__init__.py:30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order,protected-access,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_distutils\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'distutils'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize, sent_tokenize\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioSegment\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfutures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor, as_completed\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/VS Code/RetentionInsightEngine/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1462\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1460\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1462\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1463\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/VS Code/RetentionInsightEngine/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1474\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1475\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1476\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1477\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nNo module named 'distutils'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import speech_recognition as sr\n",
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from pydub import AudioSegment\n",
    "from transformers import pipeline\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hoobot/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hoobot/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MP3 to WAV for easier processing by SpeechRecognition\n",
    "def convert_audio(input_file):\n",
    "    sound = AudioSegment.from_mp3(input_file)\n",
    "    output_file = \"converted_file.wav\"\n",
    "    sound.export(output_file, format=\"wav\")\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Transcribe audio to text\n",
    "def transcribe_audio(file_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(file_path) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio_data)\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            return \"Google Speech Recognition could not understand audio\"\n",
    "        except sr.RequestError as e:\n",
    "            return \"Could not request results from Google Speech Recognition service; {0}\".format(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split video to 30 second chunks for faster processing and less chance of error\n",
    "def convert_and_chunk_audio(input_file, output_folder=\"audio_chunks\", chunk_length_ms=30000):\n",
    "    # Create the output folder if it doesn't already exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    sound = AudioSegment.from_mp3(input_file)\n",
    "    chunks = []\n",
    "\n",
    "    for i in range(0, len(sound), chunk_length_ms):\n",
    "        chunk = sound[i:i+chunk_length_ms]\n",
    "        chunk_name = f\"chunk{i//chunk_length_ms}.wav\"\n",
    "        chunk_path = os.path.join(output_folder, chunk_name)  # Save chunks to the specified folder\n",
    "        chunk.export(chunk_path, format=\"wav\", parameters=[\"-ar\", \"16000\"])\n",
    "        chunks.append(chunk_path)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_transcribe_audio(chunks):\n",
    "    transcriptions = []\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_chunk = {executor.submit(transcribe_audio, chunk): chunk for chunk in chunks}\n",
    "        for future in as_completed(future_to_chunk):\n",
    "            chunk = future_to_chunk[future]\n",
    "            try:\n",
    "                transcription = future.result()\n",
    "                transcriptions.append(transcription)\n",
    "            except Exception as exc:\n",
    "                print(f'Chunk {chunk} generated an exception: {exc}')\n",
    "    return \" \".join(transcriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_file(input_file):\n",
    "    chunks = convert_and_chunk_audio(input_file)\n",
    "    full_transcription = parallel_transcribe_audio(chunks)\n",
    "    print(\"Full Transcription:\", full_transcription)\n",
    "\n",
    "    with open(\"transcribed_text.txt\", \"w\") as text_file:\n",
    "        text_file.write(full_transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Transcription: what's all the food was free and it was fantastic and when I first got in I couldn't understand why anyone would ever want to leave the place like I had worked so hard to get into Google and it was for me a dream come true I have been applying to try to get in for many years and I had felt the interview process multiple times actually like three times or something and on my last attempt I remember the interviewers even telling me why you must really want to get into Google because our records show that you just keep and you know it was it was great not before I got into Google I would be one of those people who would just go like Costco and just get as many samples as I could and that would be my lunch I would love food samples and I might go Trader Joe's and grab their free coffee and I might go to chocolate shops and just get free samples everywhere and you know I was just hungry and starving basically everywhere I went and after Google that kind of changed me a little bit basically I was able to get as many free samples as I wanted that Google because and I was like yeah I just really want to get in and so when I got in I couldn't fathom why anybody would ever want to leave the company it didn't make sense to me there was no place better than Google in my opinion and they also allow you to switch teams too so if the team or work ever got boring you could just switch to another team you give me switch to another location if you wanted to so they had you covered on all sorts of areas and I think for that reason the tenure is hi and welcome back to another episode of the tech lead my name is the tech lead and I will be the tech lead today I wanted to talk about why I left my six-figure job at Google because for a lot of people they imagine that once they get into Google it will be happily ever after from there on out like it's a great company to work for it's kind of the lifelong dream for a lot of people and once they get in they imagine they'll just be there forever they would basically have it made but that's not actually how it plays out in reality and you may be surprised to know that the average 10 year of a Google engineer is like 3.2% only and and that's actually on the high end and for other companies is even less now I was working as a software engineer Tech lead on the YouTube IOS app and you know it was a six-figure salary very good pay good compensation very nice benefits free food everywhere free drinks good parties occasional trips like we had annual ski trips add Youth and he just wanted to go out and travel for a few months and yeah I think that makes sense like honestly thought that was a little silly when I first heard it because I had just finished traveling myself and I was a little disillusioned by travel I didn't really think it was so cool of a thing anymore so giving up a career to just basically I knew that he would be back and within three months he was back basically asking for his job again you don't really need that much time to travel like you a little bit longer there at other places and it's a great company over to work for but throughout my time I did see people on my team leave and I can tell you a few of their stories like one guy had basically gotten into Google right after college and he just worked for years at the company after that and he never had the chance to travel and I can understand that and so he wanted to take some time off to just travel full time and fulfill his dreams of going to Tahiti and going all over the place and he had money I think that you can travel for years and years but in reality after about 2 to 4 weeks of traveling you're basically done like you're exhausted and you want to sit down and rest but anyway he's doing fine he's great and I think that in order to get even a few months to go and travel you may need to quit your job anyway like I'm not sure if anyone's going to just allow you to stay with the company and just take a few months off like even if you can promise you'll be back after that sure amount of time like I don't know if they'll do it they might I've heard other people towing companies like uber you know these are unicorns startups and it's a shot and making big money maybe but in reality I'm not sure I recommend that path really either because I think that these unicorn startups they never really tell you how much money you're actually getting how much how many shares they just tell you you get like 50 million shares but in reality you have no idea what valuation that's going to be at and what percentage of the company you've got so it's really a leap of faith that you're taking for the company and basically I'm not sure if that's really that great of an option but could be especially because when people from large tech companies like Google go into startups they get better positions and they can like you know maybe maybe get more control more responsibilities and develop person anymore so yeah I think that could be interesting actually other people I know have gone to other large tech companies and similar categories I've seen some Junior Engineers just quit to go run their own startups and and again I'm not really sure that's really great path because I think it's good experience to basically like just work in the large tech company like Google and just learn the ropes and the chances of a startup succeeding are actually perhaps far lower than you might imagine like a few years over at Google you be promoted a few times and your salary will probably go up so I think kind of in my mind like maybe a junior engineer who gone to Google is taking it for granted and thinking it's easy to do it but I don't think it's that easy in reality like at least not it wasn't for me so it took me quite a while to get in and yeah one thing to note though is if you've gotten it before you may be able to get back in again another time like I've heard a few stories of people who left and then later came back so if people want to go out and explore some other route like startups or something like that maybe something really promising and then if it doesn't go well they come back I think that's actually a fine route actually so I think what's interesting do average year amount that people start leaving companies and I just felt that it was about time to broaden my experience take a look around see what else is out there you know basically once I was able to get into Google having that on your resume really helps open a lot of doors and options for you like the world becomes your pick basically like anything else that looks interesting to you people will probably at least give you an interview and talk to you about whatever opportunities so so I went to Google and listen to consider is that when you first get into one of these top tech companies you think oh it's so great and you'll never going to leave but over time that actually becomes your Baseline and it's not really at the end of a journey it is the continuation of your journey and and basically you owe it to yourself to see how much further you can go whether within that same company or if another company or another path is going to be for you ask for myself I hit three and a half years pretty similar to say like the 3. who was stunned by all the amazing technology they've got their like it's really like living in the future there like there are so many cool internal tools and systems and everything is set up so well and a lot of this is proprietary internal software that has yet to be open-sourced or released for public usage and you know some of these may not be released for years or forever because they're integrated so well with Google's internal tools that basically some of these tools may just be Inseparable so I thought if I got into Google and there is this whole hidden secret world of technology just within that company that was not public for anyone else to see and the only way to get access to see that whole world was to get into the company I wanted to see what was behind the walls of other companies as well because I was just so fascinated by the internal technology that has yet to be released and I wanted to see how other companies were being set up inside what tools they had I wanted to see at the workflow was like what the coach was like what their vision is you know every company has its own culture its own pros and cons their mission their you know like for example Google is known as a very engineering-based culture they have strong processes good code reviews good ownership and they really focus on just like well-crafted solid engineering and that's great however one criticism has been that they move a little bit too slowly and the other companies may have another whole set of different cultures so it was just interesting for me to think about play getting into heaven and then you just live there happily ever after forever it's only good for about 3.2 years on average for most people and after that they go on and find some other things so if your life goal is to get into Google just remember that for the average person after just 3.25 and they find some other place to go maybe it's a start-up maybe it's another company and so there's more than one play to get into these other places like if somebody joins Google and after a few years gets into Uber maybe you should just apply into Uber or if someone goes to Google and then decides to go to a startup maybe he's just a fly straight to that startup and you know that's kind of like a shortcut now maybe your position and pay would not be as high but I would say that probably more than position or pay is just being within the walls of a company that will kind of Define that's sort of Lifestyle you're going to have say hi sunny sunny it kind of got the best of my curiosity and I started taking a look around and wanted to apply to other companies and see what else is out there eventually I found the company that seemed quite interesting to me and I wanted to see what was behind the walls take a look and yeah that was basically the path that I took anyway the takeaway I wanted to get across to you was a lot of people are trying to get into Google and they can't and I want you to realize that it's not play really wanted to do so I might encourage you to think a little bit longer term a little bit broader than just getting into a company like think about the overall lifestyle that you're trying to craft for yourself and for the average person Google is not the destination it is just one piece of their journey in software engineering so they'll do for me I hope you enjoyed the episode give it a like And subscribe and I will see you next time you know most people within the company are living very similar Lifestyles they have the same food they they go in at the same time they work on the same problems and all that and and I would imagine that especially like I've seen Junior Engineers they come into Google they work one year and then they're done and they go do their startup like for those people maybe what they were really looking for was just a bit of validation they just wanted to feel that they could be certified as a actual software engineer and after that there were other things that\n"
     ]
    }
   ],
   "source": [
    "# Replace 'Interview_Audio.mp3' with the exact audio file\n",
    "# process_audio_file(\"Exit Interview Questions from We.mp3\")\n",
    "process_audio_file(\"Why I left my job at Google (as a software engineer).mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis Function\n",
    "def analyze_sentiment(text):\n",
    "    # Load the sentiment analysis pipeline\n",
    "    classifier = pipeline('sentiment-analysis')\n",
    "    # Analyze the sentiment\n",
    "    results = classifier(text)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the Sentiment of Transcribed Text\n",
    "def analyze_transcribed_file(file_path):\n",
    "    # Assuming you have already run the process_audio_file function and have the transcribed text saved\n",
    "    with open(file_path, \"r\") as file:\n",
    "        transcribed_text = file.read()\n",
    "        \n",
    "    # Break the text into smaller chunks if necessary (depending on the size and the limitations of the model)\n",
    "    # For simplicity, we'll assume the text is short enough to be processed in one go\n",
    "    sentiment_results = analyze_sentiment(transcribed_text)\n",
    "    \n",
    "    # Print the results\n",
    "    for result in sentiment_results:\n",
    "        print(f\"Sentiment: {result['label']}, Confidence: {result['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example: Analyze the sentiment of the previously transcribed audio file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m transcribed_text_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscribed_text.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Ensure this is the correct path to your transcribed text file\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43manalyze_transcribed_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranscribed_text_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m, in \u001b[0;36manalyze_transcribed_file\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m     transcribed_text \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Break the text into smaller chunks if necessary (depending on the size and the limitations of the model)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# For simplicity, we'll assume the text is short enough to be processed in one go\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m sentiment_results \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranscribed_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m sentiment_results:\n",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m, in \u001b[0;36manalyze_sentiment\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_sentiment\u001b[39m(text):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Load the sentiment analysis pipeline\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     classifier \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentiment-analysis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Analyze the sentiment\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     results \u001b[38;5;241m=\u001b[39m classifier(text)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/pipelines/__init__.py:905\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 905\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    915\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    916\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/pipelines/base.py:230\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    234\u001b[0m     )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    236\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task\n",
      "\u001b[0;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "# Example: Analyze the sentiment of the previously transcribed audio file\n",
    "transcribed_text_file = \"transcribed_text.txt\"  # Ensure this is the correct path to your transcribed text file\n",
    "analyze_transcribed_file(transcribed_text_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
